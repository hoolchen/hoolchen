<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta name="keywords" content="hexo,ä¸ªäººåšå®¢,blog">
  <meta name="description" content="æŸæŸçš„ä¸ªäººåšå®¢">
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://busuanzi.ibruce.info">
  
  <link rel="dns-prefetch" href="https://widget.daovoice.io">
  <link rel="dns-prefetch" href="https://widget-static-cdn.daovoice.io">
  <link rel="dns-prefetch" href="https://im.daovoice.io">
  
  
  <link rel="dns-prefetch" href="https://hm.baidu.com/">
  
  
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="https://api.github.com">
  <link rel="dns-prefetch" href="https://avatars3.githubusercontent.com">
  
  <link rel="stylesheet" type="text/css" href="/./style/main.d9e3dd.css">
	<link rel="shortcut icon" href="/favicon.ico" title="Favicon">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
	<title>éšæœºæ¢¯åº¦ä¸‹é™</title>
  
  <script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?awwssw1snsnsnn1ndndnndnd99j";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();
  </script>
  
  
    <script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/123456.js","daovoice");daovoice('init',{app_id: "123456"});daovoice('update');
  </script>
  
</head>
<body>
<canvas id="pattern-placeholder" height="230"></canvas>
<div class="navbar-header">
  <a class="blog-title" href="/">hoolchencodes</a>
  <a class="face-img" href="/">
    <img src="https://tva3.sinaimg.cn/crop.0.0.200.200.180/005Kc3C1jw8f2uep0hhkvj305k05k3yk.jpg">
  </a>
</div>
<main>
  <div class="article-title">
    
  
  <h1 class="title">
    éšæœºæ¢¯åº¦ä¸‹é™
  </h1>
  


    <ul class="article-info">
      <li>
        å‘å¸ƒ
        <time datetime="2019-03-27T07:58:34.000Z" itemprop="datePublished">2019-03-27</time>
      </li>
      <li>
        
    æ›´æ–° <time datetime="2019-03-27T08:57:39.998Z" itemprop="dateUpdated">2019-03-27</time>

      </li>
      <li id="busuanzi_container_page_pv">
        é˜…è¯» <span id="busuanzi_value_page_pv"></span>
      </li>
    </ul>
  </div>
  <div class="container">
    <div class="article">
      <div class="content">
        
        <h2 id="Exercise-1"><a href="#Exercise-1" class="headerlink" title="Exercise 1"></a>Exercise 1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_data = np.loadtxt(<span class="string">"dataForTesting.txt"</span>)</span><br><span class="line">train_data = np.loadtxt(<span class="string">"dataForTraining.txt"</span>)</span><br></pre></td></tr></table></figure>
<p>æŸå¤±å‡½æ•°å¦‚ä¸‹ï¼Œå‘é‡åŒ–è®¡ç®—å…¬å¼<br>$$(1/2<em>m)</em>(X.T.dot(X.dot(gradient)-y))$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è®¡ç®—æŸå¤±</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(x, y, gradient)</span>:</span></span><br><span class="line">    s = y.shape[<span class="number">0</span>] <span class="comment">#æ ·æœ¬æ•°é‡</span></span><br><span class="line">    C = x.dot(gradient) - y;</span><br><span class="line">    J2 = (C.T.dot(C)) / (<span class="number">2</span>*s)</span><br><span class="line">    <span class="keyword">return</span> J2</span><br></pre></td></tr></table></figure>
<p>éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œå³<br>Loop {<br>  for i=1 to m,{<br>    $$Î¸_j := Î¸<em>j + Î±(y^i - h</em>Î¸(x^i))x_j^i$$<br>  }<br>}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ¢¯åº¦ä¸‹é™</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span><span class="params">(x, y, gradient, lr, loss_train, loss_test, p_x, py, m, iter_count)</span>:</span></span><br><span class="line">    s = y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        r = random.randint(<span class="number">0</span>, s<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">            gradient[j, <span class="number">0</span>] = gradient[j, <span class="number">0</span>] - lr * x[r, j] * (x[r, :].dot(gradient) - y[r, <span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> (int((i + <span class="number">1</span>) % iter_count) == <span class="number">0</span>):</span><br><span class="line">            loss_train[int(i / iter_count)] = computeCost(x, y, gradient)</span><br><span class="line">            loss_test[int(i / iter_count)] = computeCost(p_x, py, gradient)</span><br><span class="line">    <span class="keyword">return</span> gradient, loss_train, loss_test</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç‰¹å¾å¢ç»´</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">featureAddition</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.hstack([x, np.ones((x.shape[<span class="number">0</span>], <span class="number">1</span>))])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#é¢„æµ‹</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(data, mean, std, gradient)</span>:</span></span><br><span class="line">    data = (data - mean) / std;</span><br><span class="line">    data = np.hstack([data, np.ones((data.shape[<span class="number">0</span>], <span class="number">1</span>))])</span><br><span class="line">    price = data.dot(gradient)</span><br><span class="line">    <span class="keyword">return</span> price</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">3</span> <span class="comment">#ç‰¹å¾æ•°é‡</span></span><br><span class="line">gradient = np.zeros((n,<span class="number">1</span>)) <span class="comment">#åˆå§‹åŒ–æ¢¯åº¦</span></span><br><span class="line">lr = <span class="number">0.00015</span> <span class="comment">#å­¦ä¹ ç‡</span></span><br><span class="line">m = <span class="number">1500000</span> <span class="comment">#è¿­ä»£æ¬¡æ•°</span></span><br><span class="line">iter_count = <span class="number">100000</span></span><br><span class="line">loss_test = np.zeros((int(m / iter_count), <span class="number">1</span>)) <span class="comment">#è®­ç»ƒæ ·æœ¬è¯¯å·®ï¼ˆ100000æ­¥ä¸€æ¬¡ï¼‰</span></span><br><span class="line">loss_train = np.zeros((int(m / iter_count), <span class="number">1</span>))<span class="comment">#æµ‹è¯•æ ·æœ¬è¯¯å·®ï¼ˆ100000æ­¥ä¸€æ¬¡ï¼‰</span></span><br><span class="line">X = train_data[:, (<span class="number">0</span>,<span class="number">1</span>)].reshape((<span class="number">-1</span>,<span class="number">2</span>))<span class="comment">#è®­ç»ƒæ ·æœ¬çš„X</span></span><br><span class="line">Y = train_data[:, <span class="number">2</span>].reshape((<span class="number">-1</span>,<span class="number">1</span>))    <span class="comment">#è®­ç»ƒæ ·æœ¬çš„Y</span></span><br><span class="line">px = test_data[:, (<span class="number">0</span>, <span class="number">1</span>)].reshape((<span class="number">-1</span>, <span class="number">2</span>))<span class="comment">#æµ‹è¯•æ ·æœ¬çš„X</span></span><br><span class="line">py = test_data[:, <span class="number">2</span>]. reshape((<span class="number">-1</span>, <span class="number">1</span>))    <span class="comment">#æµ‹è¯•æ ·æœ¬çš„Y</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = featureAddition(X) <span class="comment">#è®­ç»ƒæ ·æœ¬çš„ç‰¹å¾å¢ç»´</span></span><br><span class="line">x_test = featureAddition(px) <span class="comment">#æµ‹è¯•æ ·æœ¬çš„ç‰¹å¾å¢ç»´</span></span><br><span class="line">gradient, loss_train, loss_test = gradientDescent(x_train, Y, gradient, lr, loss_train, loss_test, x_test, py, m, iter_count)</span><br><span class="line">print(<span class="string">"æ¢¯åº¦å¦‚ä¸‹\n"</span>,gradient)</span><br></pre></td></tr></table></figure>
<pre><code>æ¢¯åº¦å¦‚ä¸‹
 [[nan]
 [nan]
 [nan]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è®­ç»ƒæ ·æœ¬çš„è¯¯å·®</span></span><br><span class="line">plt.plot(loss_train)</span><br><span class="line">plt.ylabel(<span class="string">"loss"</span>);</span><br><span class="line">plt.xlabel(<span class="string">"iter count/(100000)"</span>)</span><br><span class="line">plt.title(<span class="string">"loss_train function"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &apos;loss_train function&apos;)
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_11_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æµ‹è¯•æ ·æœ¬çš„è¯¯å·®</span></span><br><span class="line">plt.plot(loss_test)</span><br><span class="line">plt.ylabel(<span class="string">"loss"</span>);</span><br><span class="line">plt.xlabel(<span class="string">"iter count/(100000)"</span>)</span><br><span class="line">plt.title(<span class="string">"loss_test function"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &apos;loss_test function&apos;)
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_12_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#é¢„æµ‹ä»·æ ¼ï¼Œ æ©™è‰²ä¸ºæ ·æœ¬ä»·æ ¼ï¼Œè“è‰²ä¸ºé¢„æµ‹ä»·æ ¼</span></span><br><span class="line">mean = <span class="number">0</span></span><br><span class="line">std = <span class="number">1</span></span><br><span class="line">price = predict(px, mean, std, gradient)</span><br><span class="line"><span class="comment"># print("é¢„æµ‹ä»·æ ¼å¦‚ä¸‹\n", price)</span></span><br><span class="line"><span class="comment"># print("æ ·æœ¬ä»·æ ¼å¦‚ä¸‹\n", py)</span></span><br><span class="line">plt.plot(price)</span><br><span class="line">plt.plot(py)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x236ec5c1898&gt;]
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_13_1.png" alt="png"></p>
<p>ä»ä¸Šé¢å›¾å¯ä»¥çœ‹å‡ºï¼Œç”±äºå­¦ä¹ ç‡åå¤§ï¼Œå¯¼è‡´æ¢¯åº¦å˜åŒ–å¹…åº¦è¿‡å¤§ï¼Œlosså¢é•¿å¤ªå¿«ï¼Œå¯¼è‡´æ¯æ¬¡éƒ½è¶Šè¿‡æœ€ä¼˜è§£ã€‚</p>
<h2 id="Exercise-2"><a href="#Exercise-2" class="headerlink" title="Exercise 2"></a>Exercise 2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gradient = np.zeros((n,<span class="number">1</span>)) <span class="comment">#åˆå§‹åŒ–æ¢¯åº¦</span></span><br><span class="line">lr = <span class="number">0.00002</span> <span class="comment">#å­¦ä¹ ç‡</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gradient, loss_train, loss_test = gradientDescent(x_train, Y, gradient, lr, loss_train, loss_test, x_test, py, m, iter_count)</span><br><span class="line">print(<span class="string">"æ¢¯åº¦å¦‚ä¸‹\n"</span>,gradient)</span><br></pre></td></tr></table></figure>
<pre><code>æ¢¯åº¦å¦‚ä¸‹
 [[  6.84244681]
 [-72.22161681]
 [ 70.50986559]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è®­ç»ƒæ ·æœ¬çš„è¯¯å·®</span></span><br><span class="line">plt.plot(loss_train)</span><br><span class="line">plt.ylabel(<span class="string">"loss"</span>);</span><br><span class="line">plt.xlabel(<span class="string">"iter count/(100000)"</span>)</span><br><span class="line">plt.title(<span class="string">"loss_train function"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &apos;loss_train function&apos;)
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_18_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æµ‹è¯•æ ·æœ¬çš„è¯¯å·®</span></span><br><span class="line">plt.plot(loss_test)</span><br><span class="line">plt.ylabel(<span class="string">"loss"</span>);</span><br><span class="line">plt.xlabel(<span class="string">"iter count/(100000)"</span>)</span><br><span class="line">plt.title(<span class="string">"loss_test function"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &apos;loss_test function&apos;)
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_19_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#é¢„æµ‹ä»·æ ¼ï¼Œæ©™è‰²ä¸ºæ ·æœ¬ä»·æ ¼ï¼Œè“è‰²ä¸ºé¢„æµ‹ä»·æ ¼</span></span><br><span class="line">mean = <span class="number">0</span></span><br><span class="line">std = <span class="number">1</span></span><br><span class="line">price = predict(px, mean, std, gradient)</span><br><span class="line"><span class="comment"># print("é¢„æµ‹ä»·æ ¼å¦‚ä¸‹\n", price)</span></span><br><span class="line"><span class="comment"># print("æ ·æœ¬ä»·æ ¼å¦‚ä¸‹\n", py)</span></span><br><span class="line">plt.plot(price)</span><br><span class="line">plt.plot(py)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x236ec6f02b0&gt;]
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_20_1.png" alt="png"></p>
<p>å½“å­¦ä¹ ç‡ä»0.00015é™åˆ°0.00002ï¼Œå³å­¦ä¹ ç‡å‡å°ï¼Œlosså¢é•¿å¹…åº¦å˜å°ï¼Œå®¹æ˜“æ‰¾åˆ°æœ€ä¼˜è§£ã€‚</p>
<h2 id="Exercise-3"><a href="#Exercise-3" class="headerlink" title="Exercise 3"></a>Exercise 3</h2><p>åœ¨è¿™é‡Œï¼Œæˆ‘å¼•ç”¨ç‰¹å¾ç¼©æ”¾ï¼Œæ ‡å‡†åŒ–æ•°æ®æ ·æœ¬ç‰¹å¾çš„èŒƒå›´<br>$$x_n = \frac{x_n - mean}{sigma}$$<br>å…¶ä¸­meanä¸ºæ ·æœ¬ç‰¹å¾çš„å¹³å‡å€¼ï¼Œsigmaæ˜¯æ ·æœ¬ç‰¹å¾çš„æ ‡å‡†å·®ï¼Œå¯ä»¥å°†ç‰¹å¾çš„å°ºåº¦ç¼©æ”¾åˆ°-1åˆ°1ä¹‹é—´</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç‰¹å¾ç¼©æ”¾</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">featureNormalize</span><span class="params">(x, n)</span>:</span></span><br><span class="line">    x_norm = x</span><br><span class="line">    mean = np.zeros((<span class="number">1</span>, n<span class="number">-1</span>))</span><br><span class="line">    std = np.zeros((<span class="number">1</span>, n<span class="number">-1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n<span class="number">-1</span>):</span><br><span class="line">        mean[<span class="number">0</span>, i] = np.mean(x[:, i])</span><br><span class="line">        std[<span class="number">0</span>, i] = np.std(x[:, i])</span><br><span class="line">    x_norm = (x - mean) / std</span><br><span class="line">    <span class="keyword">return</span> x_norm, mean, std</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gradient = np.zeros((n,<span class="number">1</span>)) <span class="comment">#åˆå§‹åŒ–æ¢¯åº¦</span></span><br><span class="line">lr = <span class="number">0.0002</span> <span class="comment">#å­¦ä¹ ç‡</span></span><br><span class="line">m = <span class="number">30000</span> <span class="comment">#è¿­ä»£æ¬¡æ•°</span></span><br><span class="line">iter_count = <span class="number">1000</span></span><br><span class="line">loss_test = np.zeros((int(m / iter_count), <span class="number">1</span>)) <span class="comment">#è®­ç»ƒæ ·æœ¬è¯¯å·®ï¼ˆ10000æ­¥ä¸€æ¬¡ï¼‰</span></span><br><span class="line">loss_train = np.zeros((int(m / iter_count), <span class="number">1</span>))<span class="comment">#æµ‹è¯•æ ·æœ¬è¯¯å·®ï¼ˆ10000æ­¥ä¸€æ¬¡ï¼‰</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train, mean, std = featureNormalize(X, n) <span class="comment">#è®­ç»ƒæ ·æœ¬çš„ç‰¹å¾ç¼©æ”¾</span></span><br><span class="line">x_train = featureAddition(x_train)</span><br><span class="line">x_test, mean_test, std_test = featureNormalize(px, n) <span class="comment">#æµ‹è¯•æ ·æœ¬çš„ç‰¹å¾ç¼©æ”¾</span></span><br><span class="line">x_test = featureAddition(x_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gradient, loss_train, loss_test = gradientDescent(x_train, Y, gradient, lr, loss_train, loss_test, x_test, py, m, iter_count)</span><br><span class="line">print(<span class="string">"æ¢¯åº¦å¦‚ä¸‹\n"</span>,gradient)</span><br></pre></td></tr></table></figure>
<pre><code>æ¢¯åº¦å¦‚ä¸‹
 [[ 159.24297428]
 [-200.38232214]
 [ 400.45342326]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è®­ç»ƒæ ·æœ¬çš„è¯¯å·®</span></span><br><span class="line">plt.plot(loss_train)</span><br><span class="line">plt.ylabel(<span class="string">"loss"</span>);</span><br><span class="line">plt.xlabel(<span class="string">"iter count/(1000)"</span>)</span><br><span class="line">plt.title(<span class="string">"loss_train function"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &apos;loss_train function&apos;)
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_28_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æµ‹è¯•æ ·æœ¬çš„è¯¯å·®</span></span><br><span class="line">plt.plot(loss_test)</span><br><span class="line">plt.ylabel(<span class="string">"loss"</span>);</span><br><span class="line">plt.xlabel(<span class="string">"iter count/(1000)"</span>)</span><br><span class="line">plt.title(<span class="string">"loss_test function"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0.5, 1.0, &apos;loss_test function&apos;)
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_29_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#é¢„æµ‹ä»·æ ¼ï¼Œæ©™è‰²ä¸ºæ ·æœ¬ä»·æ ¼ï¼Œè“è‰²ä¸ºé¢„æµ‹ä»·æ ¼</span></span><br><span class="line">price = predict(px, mean, std, gradient)</span><br><span class="line"><span class="comment"># print("é¢„æµ‹ä»·æ ¼å¦‚ä¸‹\n", price)</span></span><br><span class="line"><span class="comment"># print("æ ·æœ¬ä»·æ ¼å¦‚ä¸‹\n", py)</span></span><br><span class="line">plt.plot(price)</span><br><span class="line">plt.plot(py)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x236ec910b00&gt;]
</code></pre><p><img src="/2019/03/27/æ•°æ®æŒ–æ˜ä½œä¸šä¸€/output_30_1.png" alt="png"></p>
<p>ç»è¿‡ç‰¹å¾ç¼©æ”¾ä»¥åŠåˆé€‚çš„å­¦ä¹ ç‡ï¼Œåœ¨è¾ƒçŸ­çš„è¿­ä»£æ¬¡æ•°ä¸­ï¼Œå·²å¾—åˆ°æœ€ä¼˜è§£</p>

      </div>
        <div class="support-author">
          <p>æ„Ÿè°¢æ‚¨çš„é˜…è¯»ã€‚ ğŸ™
          <a href="https://888.com/index.html" target="_blank">å…³äºè½¬è½½è¯·çœ‹è¿™é‡Œ</a>
            <!--<a class="btn-pay"  href="#pay-modal">Â¥ æ‰“èµæ”¯æŒ</a>-->
          </p>
        </div>
        <!--
            <div class="like ">
              <div class="like-button">
                <a id="like-note" href="">
                  <i class="icon-heart"></i>å–œæ¬¢
                </a>
              </div>
              <span id="likes-count">256</span>
            </div>
        -->
        <div class="otherLink">
          <div class="previous">
          </div>
          <div class="next">
          </div>
        </div>
        <div class="comments" id="comments">
          
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script type="text/javascript">
  const gitalk = new Gitalk({
    clientID: 'ca381225e22ce3127684',
    clientSecret: '7dd4984948043f76543b7d87985869470b9a31de',
    repo: 'hoolchen_comments',
    owner: 'hoolchen',
    admin: ['hoolchen'],
    id: decodeURI(location.pathname),      // Ensure uniqueness and length less than 50
    distractionFreeMode: true
  })

  gitalk.render('comments');
</script>


        </div>
      </div>
    </div>
   
</main>
<div class="footer">
  <div class="info">
    <p>
    <a href="https://hexo.io"> Hexo </a> å¼ºåŠ›é©±åŠ¨ |
      <a href="https://github.com/Youthink/hexo-themes-yearn"> Yearn </a>
      ä¸»é¢˜
    </p>
    <p>&copy;2013-2018 æŸæŸçš„åšå®¢ äº¬ICPå¤‡xxxxxxå·</p>
  </div>
</div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script>//console
  var consoleConfig = '\næ¬¢è¿è®¿é—® https://hufangyun.com ï¼Œå›´è§‚å°çŒ¿å¤§åœ£çš„åšå®¢(ã¥ï½¡â—•â€¿â€¿â—•ï½¡)ã¥ï¼\n,\næœ¬åšå®¢ä½¿ç”¨ %cHexo%c æ­å»ºï¼Œåšå®¢ä¸»é¢˜ä¸ºå°çŒ¿å¤§åœ£å¼€å‘çš„ %chexo-themes-yearn%c ~~~ ğŸ‰ğŸ‰ğŸ‰ \n\næºç  https://github.com/Youthink/hexo-themes-yearn \n\nå¦‚æœå–œæ¬¢å¯ä»¥ star æ”¯æŒä¸€ä¸‹ â¤ï¸~\n,\næ‰«æä¸‹é¢çš„äºŒç»´ç ï¼Œåœ¨æ‰‹æœºä¸ŠæŸ¥çœ‹åšå®¢ï¼\n,https://static.hufangyun.com/blog-url-qrcode-180-180.png,\n æƒ³çŸ¥é“è¿™ä¸ªæ•ˆæœå¦‚ä½•å®ç°çš„ï¼Ÿåšå®¢å†…æœç´¢ console å½©è›‹ ğŸš€ ï¼\n'.split(',');
  var canConsole = true;
  var consoleInfo = (function(consoleConfig) {
  if (!canConsole || !consoleConfig || consoleConfig.length < 1) {
    return;
  }
  var consoleColor = '#6190e8';
  var _console;
  var backgroundTextStyle = 'padding: 1px 5px;color: #fff;background: ' + consoleColor + ';'
  var textStyle = 'color: ' + consoleColor + ';';

  consoleConfig.map(o => {
    var num = (o.match(/%c/g) || []).length;
    if(/^http(s)?:\/\//.test(o)) {
      console.log('%c     ', 'background: url(' + o + ') no-repeat left center;font-size: 180px;');
      return;
    }
    if (num > 0) {
      var logArguments = [];
      for (var i = 0; i < num; i++) {
        if (i % 2 === 0) {
          logArguments.push(backgroundTextStyle);
        } else {
          logArguments.push(textStyle);
        }
      }
      (_console = console).log.apply(_console, ['%c' + o, textStyle].concat(logArguments));
      return;
    }
    console.log('%c' + o, textStyle);
  });
}(consoleConfig));</script><script type="text/javascript" src="/./js/main.d9e3dd.js"></script>

</body>
</html>
